{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b673d79d",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction: 01 - Data Cleaning and Feature Engineering\n",
    "*Date: TODO*\n",
    "*Author: Jonas Lilletvedt*\n",
    "\n",
    "--- \n",
    "\n",
    "## 1. Introduction and Setup\n",
    "\n",
    "### 1.1. Objective\n",
    "\n",
    "In this notebook we will focus on data cleaning and feature engineering. Building on the findings from our initial exploration in `00_initial_data_exploration.ipynb`, this notebook's primary objective is to construct a robust end-to-end pre-processing pipeline. This pipeline will transform raw data into clean, feature-rich dataset ready for modeling, while ensuring results are reproducible and free from data leakage.\n",
    "\n",
    "To achieve this, our pipeline will systematically perform these tasks:\n",
    "1.  **Data Cleaning and Imputation:**\n",
    "    *   Address missing data in `Age`, `Embarked`.\n",
    "    *   Normalize the positive skewed data in `Fare`.\n",
    "2.  **Advanced Feature Engineering:**\n",
    "    *   Extract `Title` from `Name` column to act as a proxy for age, sex, marriage- and social-status.\n",
    "    *   Create a binned `FamilySize` feature from `SibSp` and `Parch`.\n",
    "    *   Derive `Deck` (vertical location) and `Zone` (horizontal location) from `Cabin`.\n",
    "    *   Bin the `Age` feature to better represent the non-linear relationship to `Survived`.\n",
    "\n",
    "The entire process will be wrapped in a `scikit-learn` `Pipeline`, implemented using a set of custom transformers for our distinct logic, and a `ColumnTransformer` for standard pre-processing tasks.\n",
    "\n",
    "### 1.2 Recap of Findings from Exploratory Data Analysis\n",
    "\n",
    "The preceding data analysis (`00_initial_data_exploration.ipynb`) revealed several key insights and quality issues that will determine our work here:\n",
    "\n",
    "**Key Predictive Relationships:**\n",
    "*   **Dominant Predictors:** `Sex` and `Pclass` were found to be the strongest predictor for survival.\n",
    "    *   Females had a vastly higher survival rate (~74%) then males (~18%).\n",
    "    *   There was a clear linear relationship between passenger class and survival rate. First class passengers had a survival rate of ~63% compared to second and first class passengers ~63% and ~24% respectively.\n",
    "\n",
    "**Data Quality and Structural Issues:**\n",
    "*   **Missing Data:** Multiple columns were missing significant amounts of data.\n",
    "    *   `Cabin`(~77% missing)\n",
    "    *   `Age` (~20% missing)\n",
    "    *   `Embarked` (2 missing values)\n",
    "*   **Outliers and Skewness:** The `Fare` column show a substantial discrepancy in the 75% quantile (31$) and max value (512$).\n",
    "*   **Features Requiring Transformation:** The columns `Name`, `Ticket` and `Cabin` are not suitable for direct use but contain valuable information that can be extracted:\n",
    "    *   `Name` can be deconstructed to extract `Title` (a proxy for sex, age, marriage- and social-status) and `Surname` for family identification. \n",
    "    *   From `Cabin` we can gather positional information for `Deck` (vertical location) and `Zone` (horizontal location).\n",
    "    *   `SibSp` and `Parch`can be combined for a more powerful feature, `FamilySize`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfd0e4b",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Setup\n",
    "\n",
    "---\n",
    "\n",
    "The first step in this notebook is to load in the correct libraries followed by the train and test datasets.\n",
    "\n",
    "All modifications will be applied to both the `train` and `test` sets for consistency. To prevent data leakage and ensure our model's performance is realistically evaluated, all transformations parameters -- such as values for imputation or scaling factors -- will be extracted solely from the `train` dataset. The test must and will only be used for model evaluation, and not influence any part of the data analysis or pre-processing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3edd1c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 2.1. Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cf6be1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn tools for preprocessing and modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fff610",
   "metadata": {},
   "source": [
    "### 2.2. Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d96677e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "df_train = pd.read_csv('../data/01_raw/train.csv')\n",
    "df_test = pd.read_csv('../data/01_raw/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1273d5",
   "metadata": {},
   "source": [
    "### 2.3. Initial Inspection \n",
    "\n",
    "A quick inspection to check the dataset are loaded properly and expected. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98097ae2",
   "metadata": {},
   "source": [
    "**Dataset Shapes:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8c7b24e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (891, 12)\n",
      "Test data shape: (418, 11)\n"
     ]
    }
   ],
   "source": [
    "# Check shape of each dataset\n",
    "print(f'Training data shape: {df_train.shape}')\n",
    "print(f'Test data shape: {df_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be7adfb",
   "metadata": {},
   "source": [
    "**Data Preview:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b80a243c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check five first rows of `df_train`\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "da70bfad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check five first rows of `df_test`\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dab457",
   "metadata": {},
   "source": [
    "**Data Types and Missing Values:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d73f0689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Types and missing values for `df_train`\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "08f358c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Types and missing values for `df_test`\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d10ed65",
   "metadata": {},
   "source": [
    "Unlike our train set we also have missing values in `Fare` in addition to `Cabin` and `Age`. \n",
    "\n",
    "Now that we have gotten a feel for the data, and checked everything is working as expected we will move on to `Data Cleaning and Imputation`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac2471c",
   "metadata": {},
   "source": [
    "### 2.4. Initial Findings and Plan Adjustments\n",
    "\n",
    "The inspection confirms the missing values in `Age`, `Cabin` and `Embarked` in the training set, as we expected from the EDA.\n",
    "\n",
    "Alongside the previous findings we have also discovered missing values in the test set, this include `Age` and `Cabin` similar to the train set. In addition we the test set have one missing value in `Fare`. Thus, our pipeline must be able to handle `Fare` imputation along the previous transformers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040bf891",
   "metadata": {},
   "source": [
    "## 3. Exploratory Feature Engineering and Validation\n",
    "\n",
    "--- \n",
    "\n",
    "Feature selection is an important step before pipeline development. We will therefore perform an exploratory analysis to evaluate the value of the proposed engineered features.\n",
    "\n",
    "Thus, this section will act as an 'scratchpad' for our feature engineering ideas. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7b9501",
   "metadata": {},
   "source": [
    "### 3.1. Evaluating the `Title` feature\n",
    "\n",
    "We will begin our feature engineering exploration with `Title`. As hypothesized in the introduction, a passenger's title has the potential to be a strong proxy for age, and survival. \n",
    "\n",
    "It is crucial to evaluate `Title` first, because our `Age` imputation strategy will depend on it. We will analyze `Title`'s relationship with both variables accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "09bce557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Surname_feat</th>\n",
       "      <th>Title_feat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Braund</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>Cumings</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Heikkinen</td>\n",
       "      <td>Miss.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>Futrelle</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Allen</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked Surname_feat Title_feat  \n",
       "0      0         A/5 21171   7.2500   NaN        S       Braund        Mr.  \n",
       "1      0          PC 17599  71.2833   C85        C      Cumings       Mrs.  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S    Heikkinen      Miss.  \n",
       "3      0            113803  53.1000  C123        S     Futrelle       Mrs.  \n",
       "4      0            373450   8.0500   NaN        S        Allen        Mr.  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make copy for scratchpad\n",
    "df_scratch = df_train.copy()\n",
    "\n",
    "# Add new columns\n",
    "df_scratch['Surname_feat'] = df_scratch['Name'].str.split(',').str[0]\n",
    "df_scratch['Title_feat'] = df_scratch['Name'].str.extract(pat=' ([A-Za-z]+\\.)', expand=False)\n",
    "df_scratch.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242bb7c0",
   "metadata": {},
   "source": [
    "## 4. Building the Pre-processing and Modeling Pipeline\n",
    "\n",
    "---\n",
    "\n",
    "In this section we will construct the components for our final, end-to-end pipeline. \n",
    "\n",
    "**A Note on Project Structure:** In a production setting, all source code for the pipeline would typically be organized into a `src`directory for modularity, reusability and testing. However, for the sake of clarity and simplicity for the reader, we will define these components below. This allows the reader to follow each step of the logic directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77f432e",
   "metadata": {},
   "source": [
    "### 3.1. Custom Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8de219",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning and Imputation\n",
    "\n",
    "---\n",
    "\n",
    "Our exploratory data analysis revealed several data quality issues that must be resolved before feature engineering can start:\n",
    "\n",
    "1.  **Handle Outliers and Skewed data in `Fare`:** Apply a log-transformation to the column.\n",
    "2.  **Impute `Embarked`:** Fill the two missing values using the mode.\n",
    "3.  **Impute `Age`:** Impute the missing values in `Age`, using the median age grouped by `Title` and `Pclass`.\n",
    "\n",
    "**Note on `Cabin`:** Due to the severe amount of missing data (~77%), a simple imputation is not feasible. Instead, we will treat this as a feature engineering task by extracting positional information to create two new features: `Deck` and `Zone`. For passengers with missing cabin data, these new features will be assigned an 'Unknown' class. Consequently, the handling of `Cabin` is deferred to the `Feature Engineering` section."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titanic-survival-prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
