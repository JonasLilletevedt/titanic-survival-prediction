{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8f240ec",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction: 02 - Modeling\n",
    "*Date: 14.09.2025*\n",
    "*Author: Jonas Lilletvedt*\n",
    "\n",
    "--- \n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "### 1.1. Objective\n",
    "\n",
    "This notebook marks the second part of the Titanic Survival Prediction project: model training and evaluation. We will build directly on the pre-processing pipeline constructed in `01_data_cleaning_and_feature_engineering.ipynb`. The primary objective is to systematically train, evaluate, and tune a selection of models to find the optimal balance between predictive performance and interpretability. \n",
    "\n",
    "1. **Preparation and Pipeline Reconstruction:** We will begin by loading datasets and rebuilding the pre-processing pipeline from the previous notebook to ensure a consistent and reproducible environment.\n",
    "2. **Baseline Model Evaluation:** A selection of diverse classification models (e.g., K-NN, Random Forest, Gradient Boosting) will be used as baseline and later help us identify strategies for optimization. \n",
    "3. **Hyperparameter Tuning:** The best-performing model from the baseline evaluation will undergo systematic hyperparameter tuning using GridSearchCV. The goal is to maximize its predictive performance based on our primary evaluation metric, the F1-Score. The reasoning for selecting this metric is detailed in the section below.\n",
    "4. **Final Analysis and Iteration:** Finally, we will analyze the results and train the optimized model on the full dataset to generate final predictions for a Kaggle submission. We will conclude by exploring potential avenues for future improvements, such as alternative modeling techniques or further feature engineering.\n",
    "\n",
    "Our end goal is twofold: to develop a model that is competitive on the Kaggle leaderboard, while remaining understandable enough to provide insights into the factors that influence survival. The process will be iterative, allowing us to refine our approach based on model performance. \n",
    "\n",
    "Beyond the Leaderboard: A Focus on Interpretability\n",
    "Unlike many competition-driven projects that prioritize raw predictive power above all else, this analysis places a strong emphasis on interpretability. While achieving a high Kaggle score is a key objective, it is equally important to build a model whose decision-making process can be understood. By favoring models and features that provide clear insights—for instance, by showing why certain passengers were more likely to survive—we aim to produce not just a \"black box\" predictor, but a meaningful analysis of a historical event. This balanced approach ensures that our final result is both powerful and insightful.\n",
    "\n",
    "### 1.2 Defining Success: Beyond Simple Accuracy\n",
    "\n",
    "While accuracy is a straightforward metric, it can be misleading. A simple \"naive\" model that predicts survival for all females and death for all males achieves an accuracy of approximately 78.7% on the training data. Any model we build must therefore significantly outperform this baseline to be considered valuable.\n",
    "\n",
    "To truly understand our model's performance, we must select the right evaluation metrics for the task. The most useful evaluation metric depends on the specific problem you are trying to solve. For example, in medical screening for a virus, achieving a high Recall is more important than high Precision. We would want to identify as many infected people as possible, even if it means accepting some false positives. In other situations, however, overall Accuracy might be the primary goal.\n",
    "Applying this to the Titanic problem, our context is one of historical analysis and balanced prediction. There is no real-world cost that makes predicting a death incorrectly worse than predicting a survival incorrectly. Our goal is not just to be right, but to build a model that is equally effective at identifying both those who survived and those who did not.\n",
    "For this reason, we need metrics that reward this balance and are not skewed by the class distribution. While we will still consider overall Accuracy, our primary metric for model evaluation is:\n",
    "*   F1-Score: The harmonic mean of precision and recall. Provides an overall score between precision and recall. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b805e9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 2. Data Loading and Setup\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9fa503",
   "metadata": {},
   "source": [
    "### 2.1. Library Imports and Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a4ee99e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set seed for reproducible results\n",
    "seed = 43"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe708d8",
   "metadata": {},
   "source": [
    "### 2.2. Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "86e82f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "df_train = pd.read_csv('../data/01_raw/train.csv')\n",
    "df_test = pd.read_csv('../data/01_raw/test.csv', index_col='PassengerId')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c4cfea",
   "metadata": {},
   "source": [
    "### 2.3. Initial Inspection\n",
    "\n",
    "A quick inspection to check the datasets are loaded properly and as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaddf75",
   "metadata": {},
   "source": [
    "**Datasets Shape:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "680658e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (891, 12)\n",
      "Test data shape: (418, 10)\n"
     ]
    }
   ],
   "source": [
    "# Check shape of each dataset\n",
    "print(f'Training data shape: {df_train.shape}')\n",
    "print(f'Test data shape: {df_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a23e27",
   "metadata": {},
   "source": [
    "**Data Preview:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8c79928d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check five first rows in df_train\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "602514ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass                                          Name     Sex  \\\n",
       "PassengerId                                                                 \n",
       "892               3                              Kelly, Mr. James    male   \n",
       "893               3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "894               2                     Myles, Mr. Thomas Francis    male   \n",
       "895               3                              Wirz, Mr. Albert    male   \n",
       "896               3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "              Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                       \n",
       "892          34.5      0      0   330911   7.8292   NaN        Q  \n",
       "893          47.0      1      0   363272   7.0000   NaN        S  \n",
       "894          62.0      0      0   240276   9.6875   NaN        Q  \n",
       "895          27.0      0      0   315154   8.6625   NaN        S  \n",
       "896          22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check five first rows in df_test\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af898b38",
   "metadata": {},
   "source": [
    "### 2.4. Prepare Data for Modeling\n",
    "\n",
    "The datasets are loaded as expected. We will now separate our training data into two distinct objects:\n",
    "*   **X:** A DataFrame containing all predictor variables.\n",
    "*   **y:** A Series containing the target variable `Survived`, which we aim to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e66db967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate predictors from target\n",
    "X_train = df_train.drop('Survived', axis=1)\n",
    "y_train = df_train['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946d9a20",
   "metadata": {},
   "source": [
    "To avoid making changes on the original test data we will copy it to a separate object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d1c601b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy to avoid making changes to the original dataset\n",
    "X_test = df_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cc5179",
   "metadata": {},
   "source": [
    "Display the shapes of our new variables to ensure the separation and copy worked as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "936598c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (891, 11)\n",
      "Shape of y_train: (891,)\n",
      "Shape of X_test: (418, 10)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of X_train: {X_train.shape}')\n",
    "print(f'Shape of y_train: {y_train.shape}')\n",
    "print(f'Shape of X_test: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d946f7e",
   "metadata": {},
   "source": [
    "### 2.5. Reconstruct the Pre-processing Pipeline\n",
    "\n",
    "To make this notebook self-contained and reproducible, we will now redefine the custom transformers and the full `grand_pipeline` that were built and validated in the previous notebook. All the data transformation logic is encapsulated within a single code cell below. \n",
    "\n",
    "**A Note on Modularity vs. Narrative Flow**\n",
    "\n",
    "In a production-level software project, this logic would typically be defined in a separate python-file to be imported. However, for this project, which is designed to be a linear, narrative-driven analysis, I have chosen to explicitly include the code here. This approach ensures that the notebook tells the complete, end-to-end story. Any future changes or improvements made in later stages of the project does not affect the logic or result of previous notebooks, preserving the integrity of each step of of our analysis. Furthermore, it allows any modifications or improvements to be documented and explained at the precise moment they are introduced, for a more natural progression.\n",
    "\n",
    "All data transformation logic is therefore encapsulated within the single code cell below, which can be collapsed for easier reading of the modeling work that follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "af618220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-learn tools for preprocessing and modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class TitleExtractor(BaseEstimator,  TransformerMixin):\n",
    "    def __init__(self, rare_threshold=10):\n",
    "        self.rare_threshold = rare_threshold\n",
    "\n",
    "        # Titles with same meaning\n",
    "        self.title_synonym_mapping_ = {\n",
    "            'Mlle.': 'Miss.',\n",
    "            'Ms.': 'Miss.',\n",
    "            'Mme.': 'Mrs.'\n",
    "        }\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        titles = X['Name'].str.extract(pat=' ([A-Za-z]+\\.)', expand=False)\n",
    "        titles = titles.replace(self.title_synonym_mapping_)\n",
    "        self.non_rare_titles_ = titles.value_counts()[lambda x: x >= self.rare_threshold].index\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # Copy to avoid modifying original\n",
    "        X_copy = X.copy()\n",
    "        # Extract title \n",
    "        X_copy['Title_feat'] = X_copy['Name'].str.extract(pat=' ([A-Za-z]+\\.)', expand=False)\n",
    "        \n",
    "        # Swap titles with 'Rare' and synonym\n",
    "        X_copy['Title_feat'] = X_copy['Title_feat'].replace(self.title_synonym_mapping_)\n",
    "\n",
    "\n",
    "        X_copy['Title_feat'] = X_copy['Title_feat'].apply(lambda x: x if x in self.non_rare_titles_ else 'Rare')\n",
    "\n",
    "        return X_copy\n",
    "\n",
    "class FamilySurvialRateExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, drop_surname=True, smooth_factor=1):\n",
    "        self.drop_surname = drop_surname\n",
    "        self.smooth_factor = smooth_factor\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if y is None:\n",
    "            raise ValueError('''The FamilySurvialRateExtractor requires target variable 'y' for fitting''')\n",
    "\n",
    "        X_temp = pd.concat([X, y], axis=1)\n",
    "        X_temp['FamilyID_temp'] = self.__get_family_id(X)\n",
    "\n",
    "\n",
    "        self.family_stats_ = X_temp.groupby('FamilyID_temp').agg(\n",
    "            FamilySize_temp = ('Survived', 'size'), \n",
    "            FamilySurvivalCount_temp = ('Survived', 'sum')\n",
    "        )\n",
    "    \n",
    "        self.global_survival_rate_ = y.mean()\n",
    "        self.training_index_ = X.index\n",
    "        self.y_train_ = y\n",
    "\n",
    "        solo_travelers_stats = self.family_stats_[self.family_stats_['FamilySize_temp'] == 1]\n",
    "        \n",
    "        if not solo_travelers_stats.empty:\n",
    "            self.alone_survival_rate_ = solo_travelers_stats['FamilySurvivalCount_temp'].mean()\n",
    "        else:\n",
    "            self.alone_survival_rate_ = self.global_survival_rate_\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "\n",
    "        X_copy['FamilyID_temp'] = self.__get_family_id(X)\n",
    "\n",
    "        X_copy = X_copy.merge(self.family_stats_, on='FamilyID_temp', how='left')\n",
    "\n",
    "        # Different calculation for passengers from training set -- avoid data leakage\n",
    "        if X.index.equals(self.training_index_):\n",
    "            X_copy['FamilySurvivalCount_temp'] -= self.y_train_\n",
    "            X_copy['FamilySize_temp'] -= 1\n",
    "\n",
    "        numerator = X_copy['FamilySurvivalCount_temp'] \n",
    "        denominator = X_copy['FamilySize_temp']\n",
    "        \n",
    "        # Apply smoothing\n",
    "        smoothed_numerator = numerator + (self.smooth_factor * self.global_survival_rate_)\n",
    "        smoothed_denominator = denominator + self.smooth_factor\n",
    "\n",
    "        # Calculate FamilySurvivalRate\n",
    "        X_copy['FamilySurvivalRate_feat'] = smoothed_numerator / smoothed_denominator\n",
    "\n",
    "        # For passengers without a family from training\n",
    "        X_copy['FamilySurvivalRate_feat'] = X_copy['FamilySurvivalRate_feat'].fillna(self.global_survival_rate_)\n",
    "\n",
    "        # For passengers which travel alone we will overwrite global_survival_rate_\n",
    "        is_alone_mask = (X_copy.groupby('FamilyID_temp')['FamilyID_temp'].transform('count') == 1) & (X_copy['FamilySize_temp'] == 0 | X_copy['FamilySize_temp'].isna())\n",
    "\n",
    "        X_copy.loc[is_alone_mask, 'FamilySurvivalRate_feat'] = self.alone_survival_rate_\n",
    "\n",
    "        # Columns to drop\n",
    "        columns_to_drop = ['FamilySurvivalCount_temp', 'FamilySize_temp', 'FamilyID_temp']\n",
    "        \n",
    "        # Clean df\n",
    "        X_copy = X_copy.drop(columns_to_drop, axis=1)\n",
    "\n",
    "        return X_copy\n",
    "\n",
    "    def __get_surname(self, X):\n",
    "        # Extract surname\n",
    "        data = X.copy()\n",
    "        return data['Name'].str.extract(pat=r'^(.+)?,', expand=False)\n",
    "    \n",
    "    def __get_family_id(self, X):\n",
    "        return self.__get_surname(X) + '_' + X['Pclass'].astype(str)\n",
    "\n",
    "class AgeImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X_temp = X.copy()\n",
    "        self.median_by_title_ = X_temp.groupby('Title_feat')['Age'].median()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        X_copy['Age'] = X_copy['Age'].fillna(X_copy['Title_feat'].map(self.median_by_title_))\n",
    "        return X_copy\n",
    "\n",
    "class CabinLocationExtractor(BaseEstimator,  TransformerMixin):\n",
    "    def __init__(self, drop_original=True):\n",
    "        self.drop_original = True\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        X_copy['Deck_feat'] = X_copy['Cabin'].str.extract(pat=r'^([A-Za-z])?', expand=False).fillna('U')\n",
    "        X_copy['Zone_feat'] = pd.to_numeric(\n",
    "            X_copy['Cabin'].str.extract(pat=r'([0-9]+)', expand=False),\n",
    "            errors='coerce'\n",
    "            )\n",
    "        \n",
    "        if self.drop_original:\n",
    "            X_copy = X_copy.drop('Cabin', axis=1)\n",
    "\n",
    "        return X_copy\n",
    "    \n",
    "feature_engineering_pipeline = Pipeline(steps=[\n",
    "    ('family_survival_rate_extractor', FamilySurvialRateExtractor()),\n",
    "    ('title_extractor', TitleExtractor()),\n",
    "    ('age_imputer', AgeImputer()),\n",
    "    ('cabin_location_extractor', CabinLocationExtractor())\n",
    "])\n",
    "\n",
    "FARE_TO_LOG_TRANS = ['Fare']\n",
    "FAMILY_SURVIVAL_RATE_FEAT = ['FamilySurvivalRate_feat']\n",
    "CAT_FEATURES = ['Sex',\n",
    "                        'Embarked',\n",
    "                        'Pclass',\n",
    "                        'Title_feat',\n",
    "                        'Deck_feat'\n",
    "                        ]\n",
    "AGE_TO_BIN = ['Age']\n",
    "ZONE_TO_BIN = ['Zone_feat']\n",
    "\n",
    "\n",
    "fare_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('log_transform', FunctionTransformer(np.log1p, feature_names_out='one-to-one')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "family_survival_rate_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Simple function for pd.cut\n",
    "def apply_pd_cut(X, bins, labels):\n",
    "    series = pd.Series(np.array(X).ravel()) \n",
    "    binned_series = pd.cut(series, bins=bins, labels=labels, right=True, include_lowest=True)\n",
    "    return binned_series.to_numpy().reshape(-1, 1)\n",
    "\n",
    "# Bins for Age\n",
    "# Infant: 0-5, Child: 6-12, young-adult: 13-25, adult: 26-50, elder: 51->\n",
    "AGE_BINS = [0, 5, 12, 25, 50, np.inf]\n",
    "AGE_LABELS = ['Infant', 'Child', 'Young-Adult', 'Adult', 'Senior']\n",
    "\n",
    "def age_binner_feature_name(_, input_features):\n",
    "    return ['Age_binned']\n",
    "\n",
    "age_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('binner', FunctionTransformer(apply_pd_cut, kw_args={'bins': AGE_BINS, 'labels': AGE_LABELS}, feature_names_out=age_binner_feature_name)),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "def zone_binner_feature_name(_, input_features):\n",
    "    return ['Zone_binned']\n",
    "\n",
    "def apply_bin_zone(X, n_bins):\n",
    "    series = pd.Series(np.array(X).ravel()) \n",
    "    labels  = [f'Q{i}' for i in range(1, n_bins + 1)]\n",
    "    binned_series = pd.qcut(series, q=n_bins, labels=labels, duplicates='drop')\n",
    "\n",
    "    # Convert nans to unknown\n",
    "    binned_series = binned_series.cat.add_categories(['Unknown']).fillna('Unknown')\n",
    "    return binned_series.to_numpy().reshape(-1, 1)\n",
    "\n",
    "zone_pipeline = Pipeline(steps=[\n",
    "    ('bin_with_missing_values', FunctionTransformer(apply_bin_zone, kw_args={'n_bins': 8}, feature_names_out=zone_binner_feature_name)),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('fare_log', fare_pipeline, FARE_TO_LOG_TRANS),\n",
    "        ('family_survival_rate', family_survival_rate_pipeline, FAMILY_SURVIVAL_RATE_FEAT),\n",
    "        ('cat', categorical_pipeline, CAT_FEATURES),\n",
    "        ('age_binned', age_pipeline, AGE_TO_BIN),\n",
    "        ('zone_binned', zone_pipeline, ZONE_TO_BIN)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "grand_pipeline = Pipeline(steps=[\n",
    "    ('feature_engineering', feature_engineering_pipeline),\n",
    "    ('preprocessing', preprocessor)\n",
    "])  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a904144",
   "metadata": {},
   "source": [
    "## 3. Baseline Model Evaluation\n",
    "\n",
    "---\n",
    "With our pre-processing pipeline fully constructed, we can now proceed to the modeling phase. The first step is to establish a performance baseline by evaluating several different classification algorithms. This process will help us identify the most promising model architecture before investing time in hyperparameter tuning.\n",
    "\n",
    "As established in the introduction, our primary metric for model selection will be the F1-Score, as it provides a balanced measure of a model's performance. For a more complete picture, we will also evaluate Precision, Recall, and overall Accuracy.\n",
    "\n",
    "To obtain a reliable estimate of each model's generalization performance, we will use 5-fold cross-validation. This method helps mitigate the risk of overfitting to a single train-test split and provides a more robust foundation for our subsequent decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4c1d87",
   "metadata": {},
   "source": [
    "For our baseline we will use four different classification models. \n",
    "1. **Logistic Regression**\n",
    "2. **K-Nearest Neighbors**\n",
    "3. **Random Forest**\n",
    "4. **Gradient Boosting**\n",
    "5. **Support Vector Machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ff27879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Warnings -- Make output hard to read\n",
    "# We get a future warning from pipeline in the code block below. We have used the pipeline and functions as intended, I am therefore choosing to ignore them.\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1ed5aa4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting baseline-evaluation of models...\n",
      "\n",
      "Logistic Regression: Mean F1-Score = 0.7617\n",
      "Logistic Regression: Std-F1-Score = 0.0206\n",
      "Logistic Regression: Mean Accuracy Score = 0.8193\n",
      "Logistic Regression: Std-Accuracy Score = 0.0146\n",
      "\n",
      "K-Nearest Neighbors: Mean F1-Score = 0.7431\n",
      "K-Nearest Neighbors: Std-F1-Score = 0.0560\n",
      "K-Nearest Neighbors: Mean Accuracy Score = 0.8137\n",
      "K-Nearest Neighbors: Std-Accuracy Score = 0.0384\n",
      "\n",
      "Random Forest: Mean F1-Score = 0.7528\n",
      "Random Forest: Std-F1-Score = 0.0410\n",
      "Random Forest: Mean Accuracy Score = 0.8205\n",
      "Random Forest: Std-Accuracy Score = 0.0189\n",
      "\n",
      "Gradient Boosting: Mean F1-Score = 0.7595\n",
      "Gradient Boosting: Std-F1-Score = 0.0209\n",
      "Gradient Boosting: Mean Accuracy Score = 0.8272\n",
      "Gradient Boosting: Std-Accuracy Score = 0.0039\n",
      "\n",
      "Support Vector Machine: Mean F1-Score = 0.7647\n",
      "Support Vector Machine: Std-F1-Score = 0.0392\n",
      "Support Vector Machine: Mean Accuracy Score = 0.8361\n",
      "Support Vector Machine: Std-Accuracy Score = 0.0176\n",
      "\n",
      "Best performing model: Support Vector Machine with a mean F1-Score of 0.7647\n"
     ]
    }
   ],
   "source": [
    "# Import SKlearn models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=seed, max_iter=1000),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(random_state=seed),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=seed), \n",
    "    'Support Vector Machine': SVC(random_state=seed, probability=True)\n",
    "}\n",
    "\n",
    "scoring_metrics = ['f1', 'accuracy']\n",
    "\n",
    "# Dict for results\n",
    "results = {}\n",
    "\n",
    "print('Starting baseline-evaluation of models...\\n')\n",
    "\n",
    "# Iterate over all models\n",
    "for model_name, model in models.items():\n",
    "\n",
    "    # Train model using the pre-constructed pipeline\n",
    "    full_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', grand_pipeline),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "\n",
    "    cv_results = cross_validate(\n",
    "        full_pipeline, \n",
    "        X_train, \n",
    "        y_train, \n",
    "        cv=5, \n",
    "        scoring=scoring_metrics,\n",
    "        n_jobs=1,  \n",
    "        error_score='raise'\n",
    "    )\n",
    "\n",
    "    # Store and print the results for both metrics\n",
    "    mean_f1 = np.mean(cv_results['test_f1'])\n",
    "    std_f1 = np.std(cv_results['test_f1'])\n",
    "    mean_accuracy = np.mean(cv_results['test_accuracy'])\n",
    "    std_accuracy = np.std(cv_results['test_accuracy'])\n",
    "    \n",
    "    results[model_name] = {\n",
    "        'mean_f1': mean_f1, 'std_f1': std_f1,\n",
    "        'mean_accuracy': mean_accuracy, 'std_accuracy': std_accuracy\n",
    "    }\n",
    "\n",
    "    print(f'''{model_name}: Mean F1-Score = {results[model_name]['mean_f1']:.4f}''')\n",
    "    print(f'''{model_name}: Std-F1-Score = {results[model_name]['std_f1']:.4f}''')\n",
    "    print(f'''{model_name}: Mean Accuracy Score = {results[model_name]['mean_accuracy']:.4f}''')\n",
    "    print(f'''{model_name}: Std-Accuracy Score = {results[model_name]['std_accuracy']:.4f}\\n''')\n",
    "\n",
    "best_model_name = max(results, key=lambda k: results[k]['mean_f1'])\n",
    "\n",
    "print(f'''Best performing model: {best_model_name} with a mean F1-Score of {results[best_model_name]['mean_f1']:.4f}''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb9ddda",
   "metadata": {},
   "source": [
    "The baseline evaluation identifies the **Support Vector Machine (SVM)** as the best performing model in both key metrics:\n",
    "\n",
    "*   **Mean F1-Score:** 0.7647\n",
    "*   **Mean Accuracy:** 0.8361\n",
    "\n",
    "\n",
    "Gradient Boosting is a very close second (0.7595 F1-Score), both looks like promising candidates for further improvements.\n",
    "\n",
    "For now we will move forward with SVM and Gradient Boosting as models of choice for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0f54e6",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter Tuning\n",
    "\n",
    "---\n",
    "\n",
    "The next step is to tune the Support Vector Machine in hopes of further improving its performance. We will use GridSearchCV to systematically test different combinations of the model's key parameters to find the optimal combination for our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3a45b9",
   "metadata": {},
   "source": [
    "### 4.1. Hyperparameter Tuning Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ed7d2a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Hyperparameter Tuning for Support Vector Machine...\n",
      "F1-Score Performance:\n",
      "\n",
      "  - Baseline F1 score: 0.7647\n",
      "  - Tuned F1 score:    0.7819\n",
      "\n",
      "Accuracy Performance:\n",
      "  - Baseline Accuracy: 0.8361\n",
      "  - Accuracy of Tuned Model: 0.8384\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Best performing model from base evaluation\n",
    "svc = SVC(random_state=seed, probability=True)\n",
    "\n",
    "# Create tuning pipeline\n",
    "tuning_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', grand_pipeline),\n",
    "    ('classifier', svc)\n",
    "])\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'classifier__C': [0.1, 1, 10, 50, 100],\n",
    "    'classifier__gamma': ['scale', 'auto', 0.01, 0.1, 1], \n",
    "    'classifier__kernel': ['rbf']\n",
    "}\n",
    "\n",
    "# Create and run GridSearchCV object\n",
    "grid_search_svm = GridSearchCV(\n",
    "    tuning_pipeline, \n",
    "    param_grid,\n",
    "    cv=5, \n",
    "    scoring={'f1': 'f1', 'accuracy': 'accuracy'},\n",
    "    refit='f1',\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "# Terminal comments\n",
    "print('Starting Hyperparameter Tuning for Support Vector Machine...')\n",
    "\n",
    "# Run tuning\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "best_model_index = grid_search_svm.best_index_\n",
    "best_accuracy = grid_search_svm.cv_results_['mean_test_accuracy'][best_model_index]\n",
    "\n",
    "# Display results\n",
    "print('F1-Score Performance:')\n",
    "print(f'''\\n  - Baseline F1 score: {results['Support Vector Machine']['mean_f1']:.4f}''')\n",
    "print(f'  - Tuned F1 score:    {grid_search_svm.best_score_:.4f}')\n",
    "\n",
    "print('\\nAccuracy Performance:')\n",
    "print(f'''  - Baseline Accuracy: {results['Support Vector Machine']['mean_accuracy']:.4f}''')\n",
    "print(f'  - Accuracy of Tuned Model: {best_accuracy:.4f}')\n",
    "\n",
    "best_svm = grid_search_svm.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15462b44",
   "metadata": {},
   "source": [
    "## 4.2. Hyperparameter Tuning Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2e0321c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Hyperparameter Tuning for Gradient Boosting...\n",
      "F1-Score Performance:\n",
      "- Baseline F1 score: 0.7595\n",
      "  - Tuned F1 score:    0.7775\n",
      "\n",
      "Accuracy Performance:\n",
      "  - Baseline Accuracy: 0.8272\n",
      "  - Accuracy of Tuned Model: 0.8417\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(random_state=seed)\n",
    "\n",
    "# Create tuning pipeline\n",
    "tuning_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', grand_pipeline),\n",
    "    ('classifier', gb)\n",
    "])\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'classifier__max_depth': [3, 4, 5],\n",
    "    'classifier__subsample': [0.7, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Create and run GridSearchCV object\n",
    "grid_search_gb = GridSearchCV(\n",
    "    tuning_pipeline, \n",
    "    param_grid,\n",
    "    cv=5, \n",
    "    scoring={'f1': 'f1', 'accuracy': 'accuracy'},\n",
    "    refit='f1',\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "# Terminal comments\n",
    "print('Starting Hyperparameter Tuning for Gradient Boosting...')\n",
    "\n",
    "# Run tuning\n",
    "grid_search_gb.fit(X_train, y_train)\n",
    "\n",
    "best_model_index = grid_search_gb.best_index_\n",
    "best_accuracy = grid_search_gb.cv_results_['mean_test_accuracy'][best_model_index]\n",
    "\n",
    "# Display results\n",
    "print('F1-Score Performance:')\n",
    "print(f'''- Baseline F1 score: {results['Gradient Boosting']['mean_f1']:.4f}''')\n",
    "print(f'  - Tuned F1 score:    {grid_search_gb.best_score_:.4f}')\n",
    "\n",
    "print('\\nAccuracy Performance:')\n",
    "print(f'''  - Baseline Accuracy: {results['Gradient Boosting']['mean_accuracy']:.4f}''')\n",
    "print(f'  - Accuracy of Tuned Model: {best_accuracy:.4f}')\n",
    "\n",
    "best_gb = grid_search_gb.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b177fe",
   "metadata": {},
   "source": [
    "After hyperparameter tuning, both models showed marked improvement. The final cross-validation scores are as follows:\n",
    "\n",
    "| Model                  | Metric     | Baseline Score | Tuned Score | Change     |\n",
    "| :--------------------- | :--------- | :------------- | :---------- | :--------- |\n",
    "| **Support Vector Machine** | **F1-Score** | **0.7647**     | **0.7819**  | **+0.0172**|\n",
    "|                        | Accuracy   | 0.8361         | 0.8384      | +0.0023    |\n",
    "| **Gradient Boosting**      | F1-Score   | 0.7595         | 0.7775      | +0.0180    |\n",
    "|                        | **Accuracy**   | **0.8272**     | **0.8417**  | **+0.0145**|\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "- The **Support Vector Machine (SVM)** achieved the highest F1-score, which was our primary metric for optimization.\n",
    "- **Gradient Boosting** saw the largest overall improvement and now holds the highest accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e661f40",
   "metadata": {},
   "source": [
    "While the tuned models granted some better results, I have two possible ideas to further improvement.\n",
    "\n",
    "1. **XGBoost**: A more efficient and powerful implementation of Gradient Boosting, widely known as a go-to algorithm for machine learning competitions. It offers key advantages over the standard implementation, including advanced regularization to improve accuracy by preventing overfitting, and superior support for parallel processing to significantly reduce training times.\n",
    "\n",
    "2. **Voting Classifier**: A Voting Classifier is an ensemble method that combines the predictions from multiple models to generate a more robust final prediction.In our case, we can take our two best-tuned models (Support Vector Machine and Gradient Boosting) and average their prediction probabilities. Different models learn in different ways and therefore make different types of errors. By combining them, we can often cancel out these individual mistakes, leading to a more accurate and reliable outcome. The key to a successful ensemble is model diversity, for this reason, we will combine our SVM and Gradient Boosting models, as they have fundamentally different structures. Combining two similar models, like Gradient Boosting and XGBoost, would be less effective as they are likely to make the same kinds of errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4035a0ba",
   "metadata": {},
   "source": [
    "## 5. Exploring further Improvements with XGBoost\n",
    "\n",
    "---\n",
    "\n",
    "In this section we will investigate if XGBoost provides any significant gain in performance compared to our previous two best models (SVM and Gradient Boosting)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df90d7b6",
   "metadata": {},
   "source": [
    "### 5.1.\n",
    "\n",
    "\n",
    "Lets start by making a baseline XGBoost model, before diving into hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ab17ffca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting baseline-evaluation of XGBoost...\n",
      "\n",
      "F1-Score Performance:\n",
      "- Mean F1-Score: 0.7585\n",
      "  - Std F1-Score:    0.0247\n",
      "\n",
      "Accuracy Performance:\n",
      "  - Mean Accuracy: 0.8272\n",
      "  - Std Accuracy: 0.0081\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define models\n",
    "xgb = XGBClassifier(random_state=seed)\n",
    "model_name = 'XGBoost'\n",
    "\n",
    "scoring_metrics = ['f1', 'accuracy']\n",
    "\n",
    "print('Starting baseline-evaluation of XGBoost...\\n')\n",
    "\n",
    "# Train model using the pre-constructed pipeline\n",
    "full_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', grand_pipeline),\n",
    "    ('classifier', xgb)\n",
    "])\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    full_pipeline, \n",
    "    X_train, \n",
    "    y_train, \n",
    "    cv=5, \n",
    "    scoring=scoring_metrics,\n",
    "    n_jobs=1,  \n",
    "    error_score='raise'\n",
    ")\n",
    "\n",
    "# Store and print the results for both metrics\n",
    "xgb_mean_f1 = np.mean(cv_results['test_f1'])\n",
    "xgb_std_f1 = np.std(cv_results['test_f1'])\n",
    "xgb_mean_accuracy = np.mean(cv_results['test_accuracy'])\n",
    "xgb_std_accuracy = np.std(cv_results['test_accuracy'])\n",
    "\n",
    "print('F1-Score Performance:')\n",
    "print(f'''- Mean F1-Score: {xgb_mean_f1:.4f}''')\n",
    "print(f'  - Std F1-Score:    {xgb_std_f1:.4f}')\n",
    "\n",
    "print('\\nAccuracy Performance:')\n",
    "print(f'''  - Mean Accuracy: {xgb_mean_accuracy:.4f}''')\n",
    "print(f'  - Std Accuracy: {xgb_std_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3f21b5",
   "metadata": {},
   "source": [
    "The baseline evaluation for XGBoost is interesting. Its initial performance is nearly identical to our baseline Gradient Boosting model, with a mean F1-Score of **0.7585** and accuracy of **0.8272**.\n",
    "\n",
    "So far we do not see any improvement compared to our other models, however XGBoost performance gain often comes from its tuning capabilities and regularization parameters, which we have not utilized yet. The next step is therefore to proceed with hyperparameter tuning to see if we can squeeze some extra performance out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af4f363",
   "metadata": {},
   "source": [
    "### 5.2. Hyperparameter Tuning XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e263f387",
   "metadata": {},
   "source": [
    "**NOTE:** The cell block below can take very long to run. Especially since I have chose to set n_jobs=1 to avoid warnings for the presentation. To speed up set n_jobs=-1, this allows the model to utilize multiple cores at once, depending on your processor it might speed it up by 10x. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f63ad0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Hyperparameter Tuning for XGBoost...\n",
      "F1-Score Performance:\n",
      "\n",
      "  - Baseline F1 score: 0.7585\n",
      "  - Tuned F1 score:    0.7858\n",
      "\n",
      "Accuracy Performance:\n",
      "  - Baseline Accuracy: 0.8272\n",
      "  - Accuracy of Tuned Model: 0.8451\n"
     ]
    }
   ],
   "source": [
    "# Best performing model from base evaluation\n",
    "xgb = XGBClassifier(random_state=seed, eval_metric='logloss')\n",
    "\n",
    "# Create tuning pipeline\n",
    "tuning_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', grand_pipeline),\n",
    "    ('classifier', xgb)\n",
    "])\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid_xgb = {\n",
    "    'classifier__n_estimators': [100, 200, 400],\n",
    "    'classifier__max_depth': [3, 4, 5],\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.1],  \n",
    "    'classifier__subsample': [0.7, 0.9, 1.0],\n",
    "    'classifier__colsample_bytree': [0.7, 0.9, 1.0],\n",
    "    'classifier__reg_alpha': [0, 0.005, 0.01],   \n",
    "    'classifier__reg_lambda': [0.1, 1, 10]     \n",
    "}\n",
    "\n",
    "# Create and run GridSearchCV object\n",
    "grid_search_xgb = GridSearchCV(\n",
    "    tuning_pipeline, \n",
    "    param_grid_xgb,\n",
    "    cv=5, \n",
    "    scoring={'f1': 'f1', 'accuracy': 'accuracy'},\n",
    "    refit='f1',\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "# Terminal comments\n",
    "print('Starting Hyperparameter Tuning for XGBoost...')\n",
    "\n",
    "# Run tuning\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "best_model_index = grid_search_xgb.best_index_\n",
    "best_accuracy = grid_search_xgb.cv_results_['mean_test_accuracy'][best_model_index]\n",
    "\n",
    "# Display results\n",
    "print('F1-Score Performance:')\n",
    "print(f'''\\n  - Baseline F1 score: {xgb_mean_f1:.4f}''')\n",
    "print(f'  - Tuned F1 score:    {grid_search_xgb.best_score_:.4f}')\n",
    "\n",
    "print('\\nAccuracy Performance:')\n",
    "print(f'''  - Baseline Accuracy: {xgb_mean_accuracy:.4f}''')\n",
    "print(f'  - Accuracy of Tuned Model: {best_accuracy:.4f}')\n",
    "\n",
    "best_xgb = grid_search_xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f27caf",
   "metadata": {},
   "source": [
    "After hyperparameter tuning XGBoost is now the best performing model. It outperforms both Gradient Boost in mean accuracy and SVM in mean F1-Score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2cb4e3",
   "metadata": {},
   "source": [
    "## 6. Voting Classifier\n",
    "\n",
    "---\n",
    "\n",
    "To potentially gain a final increase in performance we will now make an ensemble model. As mentioned earlier we will use a `Voting Classifier` to combine predictions from our current best performing models, with the intention of minimizing individual errors and producing a more robust end-model. The classifier will be configured to use soft voting, a method where we average the prediction probabilities from the models to make a final prediction. This method is generally superior to hard voting as it leverages the confidence level of each model.\n",
    "\n",
    "At this point we have three contenders, SVM, XGB, and Gradient Boost. Obviously it is possible to combine all three, however since XGB and Gradient Boost rely on the same underlying algorithm they are likely to make the same mistakes, potentially outvoting SVM. Thus, we will move forward with only SVM and XGB, as XGB was in total the best performing model, and is a better fit then Gradient Boost. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe68b92a",
   "metadata": {},
   "source": [
    "### 6.1. Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "1195acbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Voting Classifier Ensemble...\n",
      "  Mean F1 Score: 0.7806\n",
      "  Mean Accuracy: 0.8440\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Retrieve best tuned models\n",
    "tuned_svm = best_svm.named_steps['classifier']\n",
    "tuned_xgb = best_xgb.named_steps['classifier']\n",
    "\n",
    "# Combine models\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('svm', tuned_svm),\n",
    "    ('xgb', tuned_xgb)\n",
    "],\n",
    "voting='soft'\n",
    ")\n",
    "\n",
    "# Create final pipeline\n",
    "ensemble_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', grand_pipeline),\n",
    "    ('ensemble', voting_clf)\n",
    "])\n",
    "\n",
    "# Terminal output\n",
    "print('Evaluating Voting Classifier Ensemble...')\n",
    "\n",
    "scoring_metrics = ['f1', 'accuracy']\n",
    "\n",
    "cv_results_ensemble = cross_validate(\n",
    "    ensemble_pipeline,\n",
    "    X_train, \n",
    "    y_train, \n",
    "    cv=5, \n",
    "    scoring=scoring_metrics,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "# Display results\n",
    "mean_f1_ensemble = np.mean(cv_results_ensemble['test_f1'])\n",
    "mean_accuracy_ensemble = np.mean(cv_results_ensemble['test_accuracy'])\n",
    "\n",
    "print(f\"  Mean F1 Score: {mean_f1_ensemble:.4f}\")\n",
    "print(f\"  Mean Accuracy: {mean_accuracy_ensemble:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f1783c",
   "metadata": {},
   "source": [
    "The results of the ensemble model is worse then XGBoost in both metrics. This indicates that SVM does capture any patterns that XGBoost already does not capture better itself. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d67d79",
   "metadata": {},
   "source": [
    "### 6.2. Interpreting the Winning Model: Feature Importance\n",
    "\n",
    "Throughout this project, a key objective has been to understand our data and explain our results. Now that we have identified XGBoost as the best-performing model, we must also analyze its internal logic to understand how it separates survivors from non-survivors.\n",
    "XGBoost is a tree-based model. This means it makes predictions by traversing down a series of decision \"trees,\" starting from a root and ending at a leaf. Each step down the tree is based on a \"question\" about a specific feature (e.g., \"Is Sex == 'male'?\"). The most important question, the ones that best split the data, are placed at the top of the trees, while smaller details are handled in the lower layers.\n",
    "A key advantage of this structure is that we can directly see which questions the model deemed most important overall. This is called feature importance, and a primary reason why XGBoost and other decision tree-based models are so widely used when we need not only good accuracy, but also interpretable results.\n",
    "\n",
    "This interpretability stands in contrast to the Support Vector Machine model we also evaluated. The SVM, particularly with its non-linear kernel, largely functions as a \"black box,\" meaning there is no direct or intuitive way to understand the results of its parameter tuning.\n",
    "While our tuned SVM was a strong contender for the best model, its lack of clear interpretability would have made it a poor choice for the final analysis, as understanding the model's logic was a key objective of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4c6f31d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12</th>\n",
       "      <th>37</th>\n",
       "      <th>9</th>\n",
       "      <th>14</th>\n",
       "      <th>1</th>\n",
       "      <th>33</th>\n",
       "      <th>23</th>\n",
       "      <th>17</th>\n",
       "      <th>27</th>\n",
       "      <th>31</th>\n",
       "      <th>...</th>\n",
       "      <th>13</th>\n",
       "      <th>25</th>\n",
       "      <th>15</th>\n",
       "      <th>35</th>\n",
       "      <th>29</th>\n",
       "      <th>36</th>\n",
       "      <th>3</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Feature</th>\n",
       "      <td>cat__Title_feat_Mr.</td>\n",
       "      <td>zone_binned__Zone_binned_Unknown</td>\n",
       "      <td>cat__Pclass_3</td>\n",
       "      <td>cat__Title_feat_Rare</td>\n",
       "      <td>family_survival_rate__FamilySurvivalRate_feat</td>\n",
       "      <td>zone_binned__Zone_binned_Q5</td>\n",
       "      <td>cat__Deck_feat_U</td>\n",
       "      <td>cat__Deck_feat_C</td>\n",
       "      <td>age_binned__Age_binned_Senior</td>\n",
       "      <td>zone_binned__Zone_binned_Q3</td>\n",
       "      <td>...</td>\n",
       "      <td>cat__Title_feat_Mrs.</td>\n",
       "      <td>age_binned__Age_binned_Child</td>\n",
       "      <td>cat__Deck_feat_A</td>\n",
       "      <td>zone_binned__Zone_binned_Q7</td>\n",
       "      <td>zone_binned__Zone_binned_Q1</td>\n",
       "      <td>zone_binned__Zone_binned_Q8</td>\n",
       "      <td>cat__Sex_male</td>\n",
       "      <td>cat__Deck_feat_F</td>\n",
       "      <td>cat__Deck_feat_G</td>\n",
       "      <td>cat__Deck_feat_T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Importance</th>\n",
       "      <td>0.469521</td>\n",
       "      <td>0.082511</td>\n",
       "      <td>0.078042</td>\n",
       "      <td>0.051583</td>\n",
       "      <td>0.032279</td>\n",
       "      <td>0.026897</td>\n",
       "      <td>0.019272</td>\n",
       "      <td>0.01713</td>\n",
       "      <td>0.01689</td>\n",
       "      <td>0.015728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005199</td>\n",
       "      <td>0.005054</td>\n",
       "      <td>0.004573</td>\n",
       "      <td>0.004465</td>\n",
       "      <td>0.003894</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             12                                37  \\\n",
       "Feature     cat__Title_feat_Mr.  zone_binned__Zone_binned_Unknown   \n",
       "Importance             0.469521                          0.082511   \n",
       "\n",
       "                       9                     14  \\\n",
       "Feature     cat__Pclass_3  cat__Title_feat_Rare   \n",
       "Importance       0.078042              0.051583   \n",
       "\n",
       "                                                       1   \\\n",
       "Feature     family_survival_rate__FamilySurvivalRate_feat   \n",
       "Importance                                       0.032279   \n",
       "\n",
       "                                     33                23                17  \\\n",
       "Feature     zone_binned__Zone_binned_Q5  cat__Deck_feat_U  cat__Deck_feat_C   \n",
       "Importance                     0.026897          0.019272           0.01713   \n",
       "\n",
       "                                       27                           31  ...  \\\n",
       "Feature     age_binned__Age_binned_Senior  zone_binned__Zone_binned_Q3  ...   \n",
       "Importance                        0.01689                     0.015728  ...   \n",
       "\n",
       "                              13                            25  \\\n",
       "Feature     cat__Title_feat_Mrs.  age_binned__Age_binned_Child   \n",
       "Importance              0.005199                      0.005054   \n",
       "\n",
       "                          15                           35  \\\n",
       "Feature     cat__Deck_feat_A  zone_binned__Zone_binned_Q7   \n",
       "Importance          0.004573                     0.004465   \n",
       "\n",
       "                                     29                           36  \\\n",
       "Feature     zone_binned__Zone_binned_Q1  zone_binned__Zone_binned_Q8   \n",
       "Importance                     0.003894                     0.001223   \n",
       "\n",
       "                       3                 20                21  \\\n",
       "Feature     cat__Sex_male  cat__Deck_feat_F  cat__Deck_feat_G   \n",
       "Importance            0.0               0.0               0.0   \n",
       "\n",
       "                          22  \n",
       "Feature     cat__Deck_feat_T  \n",
       "Importance               0.0  \n",
       "\n",
       "[2 rows x 38 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get classifier from pipeline\n",
    "best_xgb_classifier = best_xgb.named_steps['classifier']\n",
    "\n",
    "# get preprocesser from the pipeline\n",
    "best_xgb_preprocesser = best_xgb.named_steps['preprocessor']\n",
    "\n",
    "# get feature names from the ColumnTransformer\n",
    "feature_names = best_xgb_preprocesser.named_steps['preprocessing'].get_feature_names_out()\n",
    "\n",
    "# get feature importance\n",
    "feature_importance = best_xgb_classifier.feature_importances_\n",
    "\n",
    "# merge feature names with importance\n",
    "df_feat_importance = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importance\n",
    "}).sort_values(by='Importance', ascending=False).T\n",
    "\n",
    "display(df_feat_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e25c38",
   "metadata": {},
   "source": [
    "The feature importance analysis reveals a clear and logical hierarchy of predictors that the model used to determine survival.\n",
    "\n",
    "Unsurprisingly, the title `Mr.` was the single largest factor (**0.47 importance**). This aligns perfectly with our EDA findings, where adult men had the lowest survival rate. The Mr. title effectively captures this high-risk demographic, allowing the model to be highly confident about the outcome for this group from a single feature.\n",
    "\n",
    "Reinforcing the theme of socio-economic status, the next most important features were `Zone_unknown` and `Pclass_3`. `The Zone_unknown` category, which largely represents passengers in 3rd class without a registered cabin, was a powerful predictor. The model likely learned that this was correlated with both the passengers' poverty and their physical location on the ship, which may have had worse access to lifeboats. The high importance of `Pclass_3` directly confirms this finding.\n",
    "\n",
    "Crucially, our custom-engineered feature, `FamilySurvivalRate_feat`, ranked as the fifth most predictive feature. This is a significant result, as it validates the work done to create it. It shows that a passengers chance of survival is related to their other family members survival. This could be an indication of that family groups sticked together during crisis, thus surviving together.\n",
    "\n",
    "**A Note on Features with Zero Importance:** Interestingly, the `Sex` feature received a score of zero on importance by our model, in other words, it had no affect on the model's final prediction. This may seem counterintuitive, as our EDA clearly showed that `Sex` was an extremely strong predictor, with females having a much higher survival rate then males. However, this is not a fault in the model, but a sign that the model has properly identified feature redundancy and multicollinearity. The model understood the titles `Mr` and `Mrs` captures the same relationship then `Sex`, but more detailed and accurately. `Title` also captures social-, marriage-status and age, thus making `Sex` redundant. This also applies to other features (not all),  with an importance of zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f0083c",
   "metadata": {},
   "source": [
    "## 7. Kaggle Customization \n",
    "\n",
    "---\n",
    "This project had a twofold objective: creating a competitive model for the Kaggle leaderboard, while also providing an understandable model that focused not just on high accuracy, but a high F1-score.\n",
    "\n",
    "Due to the nature of the data, a good model should not only achieve a high overall accuracy but must also be able to distinguish the survivors from the rest. This is why the F1-score was a critical metric throughout our evaluation.\n",
    "\n",
    "So far, we have chosen the best model based on the F1-score, for the reasons mentioned above. However, the Kaggle leaderboard is judged solely on accuracy.\n",
    "Therefore, to maximize our competition score, we will perform one final hyperparameter search on our selected model, XGBoost. For this last step, we will optimize for accuracy instead of the F1-score, ensuring our model is aligned with the competition's evaluation metric. This newly tuned model will then be trained on the entire dataset to make our final predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2ed2d9",
   "metadata": {},
   "source": [
    "### 7.1. Final Hyperparameter Tuning for Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "525496a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Hyperparameter Tuning for Accuracy XGBoost...\n",
      "\n",
      "Accuracy Performance:\n",
      "  - Baseline Accuracy: 0.8272\n",
      "  - Accuracy of Tuned Model: 0.8485\n"
     ]
    }
   ],
   "source": [
    "# Best performing model from base evaluation\n",
    "xgb = XGBClassifier(random_state=seed, eval_metric='logloss')\n",
    "\n",
    "# Create tuning pipeline\n",
    "tuning_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', grand_pipeline),\n",
    "    ('classifier', xgb)\n",
    "])\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid_xgb = {\n",
    "    'classifier__n_estimators': [100, 200, 400],\n",
    "    'classifier__max_depth': [3, 4, 5],\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.1],  \n",
    "    'classifier__subsample': [0.7, 0.9, 1.0],\n",
    "    'classifier__colsample_bytree': [0.7, 0.9, 1.0],\n",
    "    'classifier__reg_alpha': [0, 0.005, 0.01],   \n",
    "    'classifier__reg_lambda': [0.1, 1, 10]     \n",
    "}\n",
    "\n",
    "# Create and run GridSearchCV object\n",
    "grid_search_xgb = GridSearchCV(\n",
    "    tuning_pipeline, \n",
    "    param_grid_xgb,\n",
    "    cv=5, \n",
    "    scoring={'accuracy': 'accuracy'},\n",
    "    refit='accuracy',\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "# Terminal comments\n",
    "print('Starting Hyperparameter Tuning for Accuracy XGBoost...')\n",
    "\n",
    "# Run tuning\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "best_model_index = grid_search_xgb.best_index_\n",
    "best_accuracy = grid_search_xgb.cv_results_['mean_test_accuracy'][best_model_index]\n",
    "\n",
    "# Display results\n",
    "print('\\nAccuracy Performance:')\n",
    "print(f'''  - Baseline Accuracy: {xgb_mean_accuracy:.4f}''')\n",
    "print(f'  - Accuracy of Tuned Model: {best_accuracy:.4f}')\n",
    "\n",
    "best_acc_xgb = grid_search_xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec71a8d",
   "metadata": {},
   "source": [
    "We were able to achieve a slightly higher mean accuracy compared to previously when we were focused on F1-Score.\n",
    "\n",
    "The last step and final step is to train the model on the whole train dataset, before we make our final predictions for Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd2d2e1",
   "metadata": {},
   "source": [
    "### 7.2. Training the Final Model and Generating Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f5c919a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 2)\n",
      "   PassengerId  Survived\n",
      "0          892         0\n",
      "1          893         1\n",
      "2          894         0\n",
      "3          895         0\n",
      "4          896         1\n"
     ]
    }
   ],
   "source": [
    "# Our best model\n",
    "final_kaggle_model = best_acc_xgb\n",
    "\n",
    "# Training model and the whole training dataset\n",
    "final_kaggle_model.fit(X_train, y_train)\n",
    "\n",
    "# Making final predictions\n",
    "kaggle_predictions = final_kaggle_model.predict(X_test)\n",
    "\n",
    "# Preparing Submission\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': X_test.index,\n",
    "    'Survived': kaggle_predictions\n",
    "})\n",
    "\n",
    "# Saving submission as csv\n",
    "submission.to_csv('../titanic_submission.csv', index=False)\n",
    "\n",
    "print(submission.shape)\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91da43ae",
   "metadata": {},
   "source": [
    "### 7.3.\n",
    "\n",
    "After submitting our final predictions, our model achieved a score of 0.80622, placing it at rank 276 on the leaderboard at the time of submission.\n",
    "\n",
    "This score is approximately 4 percentage points lower than our final cross-validation accuracy (0.8417). This slight drop is expected and likely reflects a combination of minor overfitting and the natural statistical differences between the training and test sets, rather than a significant flaw in the model.\n",
    "\n",
    "With further iterations on feature engineering and optimization, it is likely possible to push this score into the 0.82-0.84 range. Nevertheless, a score of 0.80622 is a good result, placing our model firmly within the top 5-10% of all legitimate submissions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titanic-survival-prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
